import React, { useState, useRef, useEffect } from 'react';
import { useNavigate, useParams } from 'react-router-dom';
import './Style/LessonDetail.css';
import lessonData from './Data/Lesson.json';

export default function LessonDetail() {
    const navigate = useNavigate();
    const { level, day } = useParams();

    // ë…¹ìŒ ê´€ë ¨ stateì™€ ref
    const [isRecording, setIsRecording] = useState(false);
    const [audioURL, setAudioURL] = useState(null);
    const [isPlaying, setIsPlaying] = useState(false);
    const [transcription, setTranscription] = useState('');
    const [isTranscribing, setIsTranscribing] = useState(false);
    const mediaRecorderRef = useRef(null);
    const audioChunksRef = useRef([]);
    const audioRef = useRef(null);

    // ë ˆë²¨ê³¼ ë‚ ì§œì— ë§ëŠ” ë ˆìŠ¨ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    const levelLessons = lessonData[level] || [];
    const currentLesson = levelLessons.find(lesson => lesson.Day === parseInt(day));

    // ë ˆë²¨ë³„ ì•„ì´ì½˜ ì„¤ì •
    const getLevelIcon = () => {
        switch (level) {
            case 'Beginner': return 'ğŸ¥';
            case 'Intermediate': return 'ğŸ¦¤';
            case 'Advanced': return 'ğŸ¦œ';
            default: return 'ğŸ“–';
        }
    };

    // ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    const transcribeAudio = async (wavBlob) => {
        try {
            setIsTranscribing(true);
            setTranscription('');

            const formData = new FormData();
            formData.append('file', wavBlob, 'recording.wav');

            const response = await fetch('/api/v1/transcribe', {
                method: 'POST',
                headers: {
                    'Authorization': 'Bearer ZATae5h-sckvlY06-aks7r-Kn2uMq'
                    // 'Content-Type'ì€ ìë™ ì„¤ì •ë˜ë¯€ë¡œ ì ˆëŒ€ ëª…ì‹œí•˜ì§€ ë§ˆì„¸ìš”.
                },
                body: formData
            });

            console.log('Response status:', response.status);
            const responseText = await response.text();
            console.log('Response text:', responseText);

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}, message: ${responseText}`);
            }

            try {
                const data = JSON.parse(responseText);
                console.log('Parsed data:', data);
                setTranscription(data.transcription || '');
            } catch (parseError) {
                console.error('JSON parsing error:', parseError);
                throw new Error('Invalid response format');
            }
        } catch (error) {
            console.error('Transcription error:', error);

            if (error.message.includes('Failed to fetch')) {
                alert('ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CORS ì •ì±…ì´ë‚˜ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
            } else {
                alert(`ìŒì„± ì¸ì‹ ì‹¤íŒ¨: ${error.message}`);
            }
        } finally {
            setIsTranscribing(false);
        }
    };
    

    // WAV ë³€í™˜ í•¨ìˆ˜
    const convertToWav = async (audioBlob) => {
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const arrayBuffer = await audioBlob.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        // WAV í—¤ë” ìƒì„±
        const length = audioBuffer.length * 2;
        const buffer = new ArrayBuffer(44 + length);
        const view = new DataView(buffer);

        // WAV íŒŒì¼ í—¤ë” ì‘ì„±
        const writeString = (offset, string) => {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        };

        writeString(0, 'RIFF');
        view.setUint32(4, 36 + length, true);
        writeString(8, 'WAVE');
        writeString(12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, 1, true);
        view.setUint32(24, audioBuffer.sampleRate, true);
        view.setUint32(28, audioBuffer.sampleRate * 2, true);
        view.setUint16(32, 2, true);
        view.setUint16(34, 16, true);
        writeString(36, 'data');
        view.setUint32(40, length, true);

        // ì˜¤ë””ì˜¤ ë°ì´í„° ì‘ì„±
        const channelData = audioBuffer.getChannelData(0);
        let offset = 44;
        for (let i = 0; i < channelData.length; i++) {
            const sample = Math.max(-1, Math.min(1, channelData[i]));
            view.setInt16(offset, sample * 0x7FFF, true);
            offset += 2;
        }

        return new Blob([buffer], { type: 'audio/wav' });
    };

    // ë…¹ìŒ ì‹œì‘ í•¨ìˆ˜
    const startRecording = async () => {
        try {
            // ê¸°ì¡´ ì˜¤ë””ì˜¤ ì •ë¦¬
            if (audioURL) {
                URL.revokeObjectURL(audioURL);
                setAudioURL(null);
            }
            if (audioRef.current) {
                audioRef.current.pause();
                audioRef.current.src = '';
            }
            setIsPlaying(false);
            setTranscription('');

            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

            // MediaRecorder ì„¤ì •
            const options = { mimeType: 'audio/webm' };
            const mediaRecorder = new MediaRecorder(stream, options);
            mediaRecorderRef.current = mediaRecorder;
            audioChunksRef.current = [];

            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    audioChunksRef.current.push(event.data);
                }
            };

            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });

                // WAVë¡œ ë³€í™˜
                const wavBlob = await convertToWav(audioBlob);
                const url = URL.createObjectURL(wavBlob);
                setAudioURL(url);

                // ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±
                if (audioRef.current) {
                    audioRef.current.src = url;
                }

                // ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                await transcribeAudio(wavBlob);
            };

            mediaRecorder.start();
            setIsRecording(true);
        } catch (err) {
            console.error('ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', err);
            alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
        }
    };

    // ë…¹ìŒ ì¤‘ì§€ í•¨ìˆ˜
    const stopRecording = () => {
        if (mediaRecorderRef.current && isRecording) {
            mediaRecorderRef.current.stop();
            mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
            setIsRecording(false);
        }
    };

    // ë§ˆì´í¬ ë²„íŠ¼ í´ë¦­ í•¸ë“¤ëŸ¬
    const handleMicClick = () => {
        if (isRecording) {
            stopRecording();
        } else {
            startRecording();
        }
    };

    // ì¬ìƒ ë²„íŠ¼ í´ë¦­ í•¸ë“¤ëŸ¬
    const handlePlayClick = () => {
        if (!audioURL || !audioRef.current) return;

        if (isPlaying) {
            audioRef.current.pause();
            setIsPlaying(false);
        } else {
            audioRef.current.play();
            setIsPlaying(true);
        }
    };

    // ì˜¤ë””ì˜¤ ì¬ìƒ ì¢…ë£Œ í•¸ë“¤ëŸ¬
    const handleAudioEnded = () => {
        setIsPlaying(false);
    };

    // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ cleanup
    useEffect(() => {
        return () => {
            // ì˜¤ë””ì˜¤ URL ì •ë¦¬
            if (audioURL) {
                URL.revokeObjectURL(audioURL);
            }
            // ë…¹ìŒ ì¤‘ì´ë©´ ì¤‘ì§€
            if (mediaRecorderRef.current && isRecording) {
                mediaRecorderRef.current.stop();
                mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
            }
        };
    }, [audioURL, isRecording]);

    if (!currentLesson) {
        return (
            <div className="lesson-detail">
                <header className="lesson-header">
                    <button className="back-button" onClick={() => navigate(-1)}>â†</button>
                    <h2>ğŸ“– Daily Learning</h2>
                </header>
                <div className="lesson-content">
                    <p>ë ˆìŠ¨ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>
                </div>
            </div>
        );
    }

    return (
        <div className="lesson-detail">
            <header className="lesson-header">
                <button className="back-button" onClick={() => navigate(-1)}>â†</button>
                <h2>ğŸ“– Daily Learning</h2>
            </header>

            <div className="lesson-content">
                <div className="lesson-title">
                    <span className="lesson-icon">{getLevelIcon()}</span>
                    <h1>Day {currentLesson.Day} - {currentLesson.Topic}</h1>
                </div>

                <div className="tutor-section">
                    <div className="tutor-avatar">ğŸ‘¤</div>
                    <div className="tutor-message">
                        <p>Hi, ICIGI</p>
                        <p>Today, we're going to learn how to use "{currentLesson.KeyExpression}" in Korean.</p>
                        <p>Let's start with a simple sentence!</p>

                        <div className="korean-example">
                            <p className="korean-text">ğŸ‘‰ "{currentLesson.ExampleSentence}"</p>
                            <p className="translation">Key Expression: {currentLesson.KeyExpression}</p>
                            <p className="meaning">ğŸ’¬ Topic: {currentLesson.Topic}</p>
                        </div>

                        <p>Try saying it out loud with me!</p>
                        <p>Ready? Let's go</p>
                    </div>
                </div>

                <div className="audio-controls">
                    <button
                        className={`audio-button ${audioURL ? 'has-audio' : ''} ${isPlaying ? 'playing' : ''}`}
                        onClick={handlePlayClick}
                        disabled={!audioURL}
                    >
                        <span className="play-icon">{isPlaying ? 'â¸' : 'â–¶'}</span>
                    </button>
                </div>

                <div className="ai-tutor-section">
                    <input
                        type="text"
                        placeholder={isTranscribing ? "ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..." : "Speak to your AI tutor!"}
                        className="ai-input"
                        value={transcription}
                        onChange={(e) => setTranscription(e.target.value)}
                        disabled={isTranscribing}
                    />
                    <div className="ai-buttons">
                        <button
                            className={`mic-button ${isRecording ? 'recording' : ''}`}
                            onClick={handleMicClick}
                            disabled={isTranscribing}
                        >
                            {isRecording ? 'â¹ï¸' : 'ğŸ¤'}
                        </button>
                        <button className="send-button">â–¶</button>
                    </div>
                </div>

                {/* ìˆ¨ê²¨ì§„ ì˜¤ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ */}
                <audio
                    ref={audioRef}
                    onEnded={handleAudioEnded}
                    style={{ display: 'none' }}
                />
            </div>
        </div>
    );
}